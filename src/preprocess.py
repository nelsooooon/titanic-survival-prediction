# -*- coding: utf-8 -*-
"""titanic_survival_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QfGutrnFoJwWro1Zu6Z8njIxsKFButvG

**Project**: Titanic Survival Prediction

**Dataset**: Titanic-Dataset.csv

# **Import Library**
"""

import pandas as pd
import numpy as np

from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, RobustScaler
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

from joblib import dump

"""# **Pre-processing**"""

class FeatureEngineer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self

    def transform(self, X):
        X_copy = X.copy()
        X_copy['Family Size'] = X_copy['SibSp'] + X_copy['Parch'] + 1
        X_copy['Fare Per Person'] = X_copy['Fare'] / X_copy['Family Size']

        X_copy['Fare Per Person'] = X_copy['Fare Per Person'].replace([np.inf, -np.inf], np.nan)

        bins = [0, 12, 19, 50, np.inf]
        labels = ['Child', 'Teenager', 'Adult', 'Senior']
        X_copy['Age Group'] = pd.cut(X_copy['Age'], bins=bins, labels=labels, include_lowest=True, right=False).astype(str)
        X_copy['Age Group'] = X_copy['Age Group'].replace('nan', 'Unknown')

        return X_copy

    def get_feature_names_out(self, input_features=None):
        new_features = ['Family Size', 'Fare Per Person', 'Age Group']
        return np.append(input_features, new_features)

class FeatureDropper(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self

    def transform(self, X):
        columns_to_drop = ['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'Fare', 'Age']

        return X.drop(columns=columns_to_drop)

    def get_feature_names_out(self, input_features=None):
        columns_to_drop = ['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'Fare', 'Age']

        return [col for col in input_features if col not in columns_to_drop]
        
def automate_preprocess(df, pipeline_path, save_path):
    """## Pipeline"""

    numerical_cols = ['Pclass', 'Family Size', 'Fare Per Person']
    categorical_cols = ['Sex', 'Embarked']
    ordinal_cols = ['Age Group']
    target_column = ['PassengerId', 'Survived']

    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', RobustScaler())
    ])

    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])

    ordinal_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('label', OrdinalEncoder())
    ])

    transformer = ColumnTransformer(
        transformers=[
        ('num', numeric_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols),
        ('ord', ordinal_transformer, ordinal_cols)
        ],
        verbose_feature_names_out=False
    )

    preprocessor = Pipeline(steps=[
        ('feature_engineer', FeatureEngineer()),
        ('feature_dropper', FeatureDropper()),
        ('transformer', transformer)
    ])
    
    dump(preprocessor, pipeline_path)
    
    X = df.drop(columns=target_column)
    y = df[target_column]

    X = preprocessor.fit_transform(X)
    feature_names = preprocessor.named_steps['transformer'].get_feature_names_out()

    df_train = pd.DataFrame(X, columns=feature_names)
    df_train[target_column] = y.reset_index(drop=True)
    
    df_train.pd.to_csv(save_path, index=False)

if __name__ == "__main__":
    train_path  = 'res/train.csv'
    df = pd.read_csv(train_path)
    
    pipeline_path = 'res/preprocessor_pipeline.joblib'
    save_path = 'res/train_preprocess.csv'
    
    automate_preprocess(df, pipeline_path, save_path)

"""End of Code.

"""